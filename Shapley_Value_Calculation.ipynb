{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af11f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from utils.Shapley_Value_Calculator import sample_mask, getShapley_freq_softmax\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09e84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tf.constant([0.4914, 0.4822, 0.4465], dtype=tf.float32)###cifar10 mean and std\n",
    "std = tf.constant([0.2023, 0.1994, 0.2010], dtype=tf.float32)\n",
    "\n",
    "def load_cifar10_dataset(batch_size):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "    return train_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a87f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output'\n",
    "model_path = \"./output_folder\"\n",
    "sample_times = 2  #000\n",
    "#num_per_class = 150\n",
    "mask_size = 3 #16\n",
    "n_per_batch = 1\n",
    "start_num = 0\n",
    "get_freq_by_dis = False\n",
    "fix_mask = False\n",
    "split_n = 1\n",
    "static_center = True\n",
    "#norm = True\n",
    "batch_size = 64\n",
    "num_classes=10\n",
    "num_per_class=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ea7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2c56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_cifar10_dataset(batch_size)\n",
    "dataset = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173274b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2\n",
      "0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/ipykernel_launcher.py:29: MatplotlibDeprecationWarning: \n",
      "The 'quality' parameter of print_jpg() was deprecated in Matplotlib 3.3 and will be removed two minor releases later. Use pil_kwargs={'quality': ...} instead. If any parameter follows 'quality', they should be passed as keyword, not positionally.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n",
      "0/2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "count = [0 for _ in range(num_classes)]\n",
    "for img, y in dataset:\n",
    "    bs, w, h, c = img.shape\n",
    "    img, y = tf.convert_to_tensor(img), tf.convert_to_tensor(y)\n",
    "\n",
    "    for k in range(bs):\n",
    "        if count[y[k].numpy()[0]] < 0:\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "        elif count[y[k].numpy()[0]] < num_per_class:\n",
    "            # 计算 Shapley 值\n",
    "            shap_value = getShapley_freq_softmax(img, y, model, sample_times, mask_size, k, n_per_batch=n_per_batch, split_n=split_n, static_center=False)\n",
    "\n",
    "            # 创建保存路径\n",
    "            shap_path = os.path.join('', \"shap_result\", f\"{y[k].numpy()[0]}\")\n",
    "            Path(shap_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # 将 shap_value 转换为图像并保存为 .jpeg 文件\n",
    "            shap_value_image = shap_value.numpy().reshape(mask_size, mask_size)  # 转换为 2D 图像\n",
    "            plt.imshow(shap_value_image, cmap='viridis')  # 使用 'viridis' 色图\n",
    "            plt.colorbar()  # 显示颜色条\n",
    "            plt.axis('off')  # 关闭坐标轴\n",
    "\n",
    "            # 保存为 JPEG 文件，设置质量参数\n",
    "            plt.savefig(os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}_freq.jpeg\"), bbox_inches='tight', pad_inches=0, quality=95)\n",
    "            plt.close()  # 关闭 plt，以释放内存\n",
    "\n",
    "            # 更新计数器\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "           # print(f\"Class {y[k].numpy()[0]} sample {count[y[k].numpy()[0]]} completed.\")\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f7fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.signal import fft2d, ifft2d\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243a2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_mean = [0.4914, 0.4822, 0.4465]\n",
    "cifar10_std = [0.2023, 0.1994, 0.2010]\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = resize(img, [32, 32])  # 假设目标是 CIFAR-10 大小\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "\n",
    "def transform_test(img):\n",
    "    # 将 PIL 图像转换为 NumPy 数组并标准化到 [0, 1] 范围\n",
    "    img = np.array(img) / 255.0\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e3adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "recon_path = os.path.join(path, \"reconstruction\")\n",
    "ifft_path = os.path.join(path, \"my_ifft\")\n",
    "shap_path = os.path.join(path, \"shap_result\")\n",
    "os.makedirs(recon_path, exist_ok=True)\n",
    "os.makedirs(ifft_path, exist_ok=True)\n",
    "classes = os.listdir(shap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bfd4fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in classes:\n",
    "    result_path = os.path.join(shap_path, i)\n",
    "    if os.path.isdir(result_path):\n",
    "        files = os.listdir(result_path)\n",
    "        for file in files:\n",
    "            with open(os.path.join(result_path, file), 'rb') as f:\n",
    "                img = Image.open(f)\n",
    "                img = img.convert('RGB')\n",
    "            img = transform_test(img)\n",
    "            freq = transform_fft(img)\n",
    "            freq_shap_file = file.split('.')[0] + \"_freq.jpeg\"\n",
    "            #freq_shap = np.load(os.path.join(result_path, freq_shap_file))\n",
    "            freq_shap = Image.open(os.path.join(result_path, freq_shap_file))\n",
    "            #mask_size = int(np.sqrt(freq_shap.size))\n",
    "            mask_size = int(np.sqrt(freq_shap.size[0] * freq_shap.size[1]))\n",
    "            freq_shap = freq_shap.reshape((1, 1, mask_size, mask_size))\n",
    "            freq_shap = np.repeat(freq_shap, 3, axis=1)\n",
    "            freq_shap = tf.image.resize(freq_shap, [img.shape[2], img.shape[3]], method='nearest')\n",
    "            mask = (freq_shap > 0).astype(np.int32)\n",
    "            mask[0, 0, img.shape[2] // 2, img.shape[3] // 2] = 0\n",
    "            pos_freq = freq * mask\n",
    "            mask = (freq_shap < 0).astype(np.int32)\n",
    "            mask[0, 0, img.shape[2] // 2, img.shape[3] // 2] = 0\n",
    "            neg_freq = freq * mask\n",
    "            pos_img = transform_ifft(pos_freq)\n",
    "            neg_img = transform_ifft(neg_freq)\n",
    "            \n",
    "            recon_class_path = os.path.join(recon_path, f\"{i}\")\n",
    "            Path(recon_class_path).mkdir(parents=True, exist_ok=True)\n",
    "            ifft_class_path = os.path.join(ifft_path, i)\n",
    "            Path(ifft_class_path).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # 保存结果\n",
    "            np.save(os.path.join(ifft_class_path, file.split('.')[0] + \"_pos.npy\"), pos_img)\n",
    "            np.save(os.path.join(ifft_class_path, file.split('.')[0] + \"_neg.npy\"), neg_img)\n",
    "            \n",
    "            max_shap = np.max(freq_shap)\n",
    "            min_shap = np.min(freq_shap)\n",
    "            for threshold in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "                mask = (freq_shap > (threshold * max_shap)).astype(np.int32)\n",
    "                mask[0, 0, img.shape[2] // 2, img.shape[3] // 2] = 1\n",
    "                pos_freq = freq * mask\n",
    "                mask = (freq_shap < (threshold * min_shap)).astype(np.int32)\n",
    "                mask[0, 0, img.shape[2] // 2, img.shape[3] // 2] = 1\n",
    "                neg_freq = freq * mask\n",
    "                pos_img = transform_ifft(pos_freq)\n",
    "                neg_img = transform_ifft(neg_freq)\n",
    "                \n",
    "                # 保存图片\n",
    "                pos_img = tf.squeeze(pos_img).numpy()\n",
    "                neg_img = tf.squeeze(neg_img).numpy()\n",
    "                Image.fromarray((pos_img * 255).astype(np.uint8)).save(os.path.join(recon_class_path, file.split('.')[0] + f\"_pos_{threshold}.png\"))\n",
    "                Image.fromarray((neg_img * 255).astype(np.uint8)).save(os.path.join(recon_class_path, file.split('.')[0] + f\"_neg_{threshold}.png\"))\n",
    "            \n",
    "            img = tf.squeeze(img).numpy()\n",
    "            Image.fromarray((img * 255).astype(np.uint8)).save(os.path.join(recon_class_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0224803",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 187956 values, but the requested shape has 62500 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3c97fd4951a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmask_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_shap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfreq_shap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mfreq_shap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_shap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 扩展为多通道\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8371\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8372\u001b[0m       return reshape_eager_fallback(\n\u001b[0;32m-> 8373\u001b[0;31m           tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8374\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8375\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8396\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8397\u001b[0m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 8398\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   8399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8400\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 187956 values, but the requested shape has 62500 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "# 处理每个类\n",
    "for class_name in classes:\n",
    "    result_path = os.path.join(shap_path, class_name)\n",
    "    #print(f\"Processing class: {shap_path}\")\n",
    "    #if not os.path.isdir(result_path):\n",
    "    #    continue\n",
    "\n",
    "    files = os.listdir(result_path)\n",
    "    \n",
    "    for file in files:\n",
    "        #if \".jpeg\" not in file or \"shap\" in file:\n",
    "        #    continue\n",
    "\n",
    "        # 加载图片\n",
    "        img_path = os.path.join(result_path, file)\n",
    "        img = preprocess_image(img_path)\n",
    "\n",
    "        # FFT 转换\n",
    "        freq = fft2d(tf.cast(img, tf.complex64))\n",
    "\n",
    "        # 加载频域 shap 值\n",
    "        #freq_shap_file = file.split('.')[0] + \"_freq.jpeg\"\n",
    "        freq_shap_file = file.split('.')[0] + \".jpeg\"\n",
    "        #print(f\"freq_shap_file = : {freq_shap_file}\")\n",
    "        freq_shap_path = os.path.join(result_path, freq_shap_file)\n",
    "        #print(f\"freq_shap_path = : {freq_shap_path}\")\n",
    "        #freq_shap = np.load(freq_shap_path)\n",
    "        freq_shap = Image.open(freq_shap_path)\n",
    "        #print(f\"freq_shap.size = : {freq_shap.size}\")\n",
    "        #print(f\"math.sqrt(freq_shap.size) = : {math.sqrt(freq_shap.size[0] * freq_shap.size[1])}\")\n",
    "        \n",
    "        mask_size = int(math.sqrt(freq_shap.size[0] * freq_shap.size[1]))\n",
    "        freq_shap = tf.reshape(freq_shap, [1, mask_size, mask_size])\n",
    "\n",
    "        # 扩展为多通道\n",
    "        freq_shap = tf.tile(freq_shap, [3, 1, 1])  # 假设 3 个通道\n",
    "        freq_shap = tf.image.resize(freq_shap, [img.shape[0], img.shape[1]])\n",
    "\n",
    "        # 构造正负掩码\n",
    "        mask_pos = tf.cast(freq_shap > 0, tf.complex64)\n",
    "        mask_neg = tf.cast(freq_shap < 0, tf.complex64)\n",
    "\n",
    "        # 去除中心频率\n",
    "        mask_pos = tf.tensor_scatter_nd_update(\n",
    "            mask_pos, [[mask_pos.shape[1] // 2, mask_pos.shape[2] // 2]], [0]\n",
    "        )\n",
    "        mask_neg = tf.tensor_scatter_nd_update(\n",
    "            mask_neg, [[mask_neg.shape[1] // 2, mask_neg.shape[2] // 2]], [0]\n",
    "        )\n",
    "\n",
    "        # 生成正负频域图片\n",
    "        pos_freq = freq * mask_pos\n",
    "        neg_freq = freq * mask_neg\n",
    "\n",
    "        pos_img = tf.math.real(ifft2d(pos_freq))\n",
    "        neg_img = tf.math.real(ifft2d(neg_freq))\n",
    "\n",
    "        # 去标准化\n",
    "        for c in range(3):\n",
    "            pos_img[..., c] = pos_img[..., c] * std[c] + mean[c]\n",
    "            neg_img[..., c] = neg_img[..., c] * std[c] + mean[c]\n",
    "\n",
    "        # 保存图片\n",
    "        recon_class_path = os.path.join(recon_path, class_name)\n",
    "        os.makedirs(recon_class_path, exist_ok=True)\n",
    "        print(f\"Saving images to {recon_class_path}\")\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_pos.jpeg\"), pos_img)\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_neg.jpeg\"), neg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ae052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6dc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a12280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b31d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fb4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6daa4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已压缩为：my_ifft.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# 定义需要压缩的文件夹路径和输出的ZIP文件路径\n",
    "folder_to_zip = 'my_ifft'\n",
    "output_zip_file = 'my_ifft.zip'\n",
    "\n",
    "# 压缩文件夹\n",
    "with zipfile.ZipFile(output_zip_file, 'w', zipfile.ZIP_DEFLATED) as zip_ref:\n",
    "    for root, dirs, files in os.walk(folder_to_zip):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, folder_to_zip)\n",
    "            zip_ref.write(file_path, arcname)\n",
    "    print(f\"文件夹已压缩为：{output_zip_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
