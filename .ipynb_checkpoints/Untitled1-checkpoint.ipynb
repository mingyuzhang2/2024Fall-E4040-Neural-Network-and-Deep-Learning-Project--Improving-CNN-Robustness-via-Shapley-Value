{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm-nwhNRQ8wy"
   },
   "source": [
    "## E4040 2024 Fall Project\n",
    "### Improving CNN Robustness via CS Shapley Value-guided Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VW8-sXpHQ69k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEhf0dW5Qgdw"
   },
   "source": [
    "### Import CIFAR-10 data and training ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hi8OkdYcSEq7"
   },
   "outputs": [],
   "source": [
    "from utils.ResNet18_trainer import ResNet18_trainer, load_cifar10_dataset#, delete_previous_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "luF2f1RQeQAu"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "log_period = 100\n",
    "epochs=100\n",
    "num_classes=10\n",
    "checkpoint_dir=\"./checkpoints\"\n",
    "model_path = \"./save_model/ResNet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_cifar10_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZaCpuzjJeP-n"
   },
   "outputs": [],
   "source": [
    "trainer = ResNet18_trainer(\n",
    "    train_ds=train_ds,\n",
    "    test_ds=test_ds,\n",
    "    num_classes=num_classes,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    decay=decay,\n",
    "    checkpoint_dir=checkpoint_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted previous checkpoints.\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    for filename in os.listdir(checkpoint_dir):\n",
    "        file_path = os.path.join(checkpoint_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(\"Deleted previous checkpoints.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_2-LAmwePdc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting from scratch.\n",
      "Training Epoch 1\n",
      "Epoch 1, Loss: 1.7864657640457153, Accuracy: 37.46800231933594, Test Loss: 1.3220628499984741, Test Accuracy: 51.26000213623047\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_1.h5\n",
      "Training Epoch 2\n",
      "Epoch 2, Loss: 1.554740309715271, Accuracy: 45.82999801635742, Test Loss: 1.198940396308899, Test Accuracy: 55.44999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_2.h5\n",
      "Training Epoch 3\n",
      "Epoch 3, Loss: 1.005147933959961, Accuracy: 64.4280014038086, Test Loss: 1.0074797868728638, Test Accuracy: 64.60000610351562\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_3.h5\n",
      "Training Epoch 4\n",
      "Epoch 4, Loss: 0.7902764081954956, Accuracy: 72.51799774169922, Test Loss: 0.7907875180244446, Test Accuracy: 72.68000030517578\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_4.h5\n",
      "Training Epoch 5\n",
      "Epoch 5, Loss: 0.6643442511558533, Accuracy: 76.97200012207031, Test Loss: 0.6481656432151794, Test Accuracy: 77.54000091552734\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_5.h5\n",
      "Training Epoch 6\n",
      "Epoch 6, Loss: 0.5734395980834961, Accuracy: 80.26200103759766, Test Loss: 0.6606226563453674, Test Accuracy: 78.13999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_6.h5\n",
      "Training Epoch 7\n",
      "Epoch 7, Loss: 0.5062116384506226, Accuracy: 82.43199920654297, Test Loss: 0.5932595729827881, Test Accuracy: 79.6500015258789\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_7.h5\n",
      "Training Epoch 8\n",
      "Epoch 8, Loss: 0.46427929401397705, Accuracy: 83.93800354003906, Test Loss: 0.6749463677406311, Test Accuracy: 77.42000579833984\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_8.h5\n",
      "Training Epoch 9\n",
      "Epoch 9, Loss: 0.4188169836997986, Accuracy: 85.68199920654297, Test Loss: 0.6134468913078308, Test Accuracy: 80.16999816894531\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_9.h5\n",
      "Training Epoch 10\n",
      "Epoch 10, Loss: 0.38102132081985474, Accuracy: 86.7820053100586, Test Loss: 0.4819166362285614, Test Accuracy: 83.4800033569336\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_10.h5\n",
      "Training Epoch 11\n",
      "Epoch 11, Loss: 0.3509272634983063, Accuracy: 87.9800033569336, Test Loss: 0.5357717871665955, Test Accuracy: 82.95000457763672\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_11.h5\n",
      "Training Epoch 12\n",
      "Epoch 12, Loss: 0.32646387815475464, Accuracy: 88.85800170898438, Test Loss: 0.5370789766311646, Test Accuracy: 82.08000183105469\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_12.h5\n",
      "Training Epoch 13\n",
      "Epoch 13, Loss: 0.29551076889038086, Accuracy: 89.69400024414062, Test Loss: 0.4150470793247223, Test Accuracy: 86.36000061035156\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_13.h5\n",
      "Training Epoch 14\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from checkpoint: ./checkpoints/ckpt_epoch_13.ckpt\n",
      "Restored from epoch 13: \n",
      "Training Epoch 14\n",
      "Epoch 14, Loss: 0.4340452253818512, Accuracy: 85.0780029296875, Test Loss: 0.6554276943206787, Test Accuracy: 78.97999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_14.h5\n",
      "Training Epoch 15\n",
      "Epoch 15, Loss: 0.36783382296562195, Accuracy: 87.40399932861328, Test Loss: 0.506313145160675, Test Accuracy: 82.87000274658203\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_15.h5\n",
      "Training Epoch 16\n",
      "Epoch 16, Loss: 0.3171531558036804, Accuracy: 89.0260009765625, Test Loss: 0.44805216789245605, Test Accuracy: 85.70999908447266\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_16.h5\n",
      "Training Epoch 17\n",
      "Epoch 17, Loss: 0.2740209698677063, Accuracy: 90.63999938964844, Test Loss: 0.5607624650001526, Test Accuracy: 83.77999877929688\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_17.h5\n",
      "Training Epoch 18\n",
      "Epoch 18, Loss: 0.24264657497406006, Accuracy: 91.65800476074219, Test Loss: 0.39384886622428894, Test Accuracy: 87.48999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_18.h5\n",
      "Training Epoch 19\n",
      "Epoch 19, Loss: 0.21621309220790863, Accuracy: 92.51800537109375, Test Loss: 0.3552367687225342, Test Accuracy: 88.69000244140625\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_19.h5\n",
      "Training Epoch 20\n",
      "Epoch 20, Loss: 0.19311963021755219, Accuracy: 93.25799560546875, Test Loss: 0.3687964081764221, Test Accuracy: 88.6500015258789\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_20.h5\n",
      "Training Epoch 21\n",
      "Epoch 21, Loss: 0.1786075085401535, Accuracy: 93.84400177001953, Test Loss: 0.35694634914398193, Test Accuracy: 89.12000274658203\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_21.h5\n",
      "Training Epoch 22\n",
      "Epoch 22, Loss: 0.15896013379096985, Accuracy: 94.39799499511719, Test Loss: 0.34409236907958984, Test Accuracy: 90.1500015258789\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_22.h5\n",
      "Training Epoch 23\n",
      "Epoch 23, Loss: 0.1429566890001297, Accuracy: 95.11199951171875, Test Loss: 0.346682071685791, Test Accuracy: 89.99000549316406\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_23.h5\n",
      "Training Epoch 24\n",
      "Epoch 24, Loss: 0.13464803993701935, Accuracy: 95.33000183105469, Test Loss: 0.3294164836406708, Test Accuracy: 90.27999877929688\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_24.h5\n",
      "Training Epoch 25\n",
      "Epoch 25, Loss: 0.11923706531524658, Accuracy: 95.84000396728516, Test Loss: 0.38335660099983215, Test Accuracy: 89.44000244140625\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_25.h5\n",
      "Training Epoch 26\n",
      "Epoch 26, Loss: 0.1073072999715805, Accuracy: 96.37000274658203, Test Loss: 0.37146854400634766, Test Accuracy: 89.8800048828125\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_26.h5\n",
      "Training Epoch 27\n",
      "Epoch 27, Loss: 0.09673662483692169, Accuracy: 96.53800201416016, Test Loss: 0.3904164135456085, Test Accuracy: 89.76000213623047\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_27.h5\n",
      "Training Epoch 28\n",
      "Epoch 28, Loss: 0.08986638486385345, Accuracy: 96.84400177001953, Test Loss: 0.3687024414539337, Test Accuracy: 90.66999816894531\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_28.h5\n",
      "Training Epoch 29\n",
      "Epoch 29, Loss: 0.08295571058988571, Accuracy: 97.09400177001953, Test Loss: 0.37290024757385254, Test Accuracy: 90.33000183105469\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_29.h5\n",
      "Training Epoch 30\n",
      "Epoch 30, Loss: 0.07910051196813583, Accuracy: 97.26799774169922, Test Loss: 0.3442302644252777, Test Accuracy: 90.68000030517578\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_30.h5\n",
      "Training Epoch 31\n",
      "Epoch 31, Loss: 0.06717751175165176, Accuracy: 97.60199737548828, Test Loss: 0.43882885575294495, Test Accuracy: 90.31999969482422\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_31.h5\n",
      "Training Epoch 32\n",
      "Epoch 32, Loss: 0.06416033208370209, Accuracy: 97.7280044555664, Test Loss: 0.41064926981925964, Test Accuracy: 90.37000274658203\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_32.h5\n",
      "Training Epoch 33\n",
      "Epoch 33, Loss: 0.06041879579424858, Accuracy: 97.83399963378906, Test Loss: 0.36623337864875793, Test Accuracy: 91.52999877929688\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_33.h5\n",
      "Training Epoch 34\n",
      "Epoch 34, Loss: 0.057075973600149155, Accuracy: 97.95600128173828, Test Loss: 0.3993799090385437, Test Accuracy: 91.11000061035156\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_34.h5\n",
      "Training Epoch 35\n",
      "Epoch 35, Loss: 0.04944576323032379, Accuracy: 98.26800537109375, Test Loss: 0.4139508008956909, Test Accuracy: 90.91999816894531\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_35.h5\n",
      "Training Epoch 36\n",
      "Epoch 36, Loss: 0.046840231865644455, Accuracy: 98.4020004272461, Test Loss: 0.4415760338306427, Test Accuracy: 91.15999603271484\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_36.h5\n",
      "Training Epoch 37\n",
      "Epoch 37, Loss: 0.04115178808569908, Accuracy: 98.62200164794922, Test Loss: 0.43622860312461853, Test Accuracy: 91.11000061035156\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_37.h5\n",
      "Training Epoch 38\n",
      "Epoch 38, Loss: 0.04097777232527733, Accuracy: 98.58200073242188, Test Loss: 0.42311111092567444, Test Accuracy: 91.43000030517578\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_38.h5\n",
      "Training Epoch 39\n",
      "Epoch 39, Loss: 0.0368071049451828, Accuracy: 98.66400146484375, Test Loss: 0.4232519268989563, Test Accuracy: 91.0999984741211\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_39.h5\n",
      "Training Epoch 40\n",
      "Epoch 40, Loss: 0.03452976047992706, Accuracy: 98.79800415039062, Test Loss: 0.4122401475906372, Test Accuracy: 91.69999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_40.h5\n",
      "Training Epoch 41\n",
      "Epoch 41, Loss: 0.03365451842546463, Accuracy: 98.86399841308594, Test Loss: 0.4409761428833008, Test Accuracy: 91.48999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_41.h5\n",
      "Training Epoch 42\n",
      "Epoch 42, Loss: 0.030635040253400803, Accuracy: 98.91999816894531, Test Loss: 0.4295096695423126, Test Accuracy: 91.56999969482422\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_42.h5\n",
      "Training Epoch 43\n",
      "Epoch 43, Loss: 0.031184805557131767, Accuracy: 98.92200469970703, Test Loss: 0.41948604583740234, Test Accuracy: 91.47999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_43.h5\n",
      "Training Epoch 44\n",
      "Epoch 44, Loss: 0.025807417929172516, Accuracy: 99.08399963378906, Test Loss: 0.42787590622901917, Test Accuracy: 91.75\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_44.h5\n",
      "Training Epoch 45\n",
      "Epoch 45, Loss: 0.024354061111807823, Accuracy: 99.18399810791016, Test Loss: 0.4510039687156677, Test Accuracy: 91.44999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_45.h5\n",
      "Training Epoch 46\n",
      "Epoch 46, Loss: 0.021947810426354408, Accuracy: 99.26799774169922, Test Loss: 0.4592773914337158, Test Accuracy: 91.57999420166016\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_46.h5\n",
      "Training Epoch 47\n",
      "Epoch 47, Loss: 0.02037518285214901, Accuracy: 99.2820053100586, Test Loss: 0.4270549714565277, Test Accuracy: 91.88999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_47.h5\n",
      "Training Epoch 48\n",
      "Epoch 48, Loss: 0.019329112023115158, Accuracy: 99.35399627685547, Test Loss: 0.4536806046962738, Test Accuracy: 91.81999969482422\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_48.h5\n",
      "Training Epoch 49\n",
      "Epoch 49, Loss: 0.018520412966609, Accuracy: 99.37200164794922, Test Loss: 0.4554612338542938, Test Accuracy: 91.79999542236328\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_49.h5\n",
      "Training Epoch 50\n",
      "Epoch 50, Loss: 0.017522260546684265, Accuracy: 99.37799835205078, Test Loss: 0.4559861719608307, Test Accuracy: 91.63999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_50.h5\n",
      "Training Epoch 51\n",
      "Epoch 51, Loss: 0.016794057562947273, Accuracy: 99.3740005493164, Test Loss: 0.4595058858394623, Test Accuracy: 91.79999542236328\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_51.h5\n",
      "Training Epoch 52\n",
      "Epoch 52, Loss: 0.016467655077576637, Accuracy: 99.43399810791016, Test Loss: 0.4645997881889343, Test Accuracy: 92.07999420166016\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_52.h5\n",
      "Training Epoch 53\n",
      "Epoch 53, Loss: 0.013585562817752361, Accuracy: 99.4939956665039, Test Loss: 0.45509153604507446, Test Accuracy: 92.22999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_53.h5\n",
      "Training Epoch 54\n",
      "Epoch 54, Loss: 0.012842031195759773, Accuracy: 99.54399871826172, Test Loss: 0.46001148223876953, Test Accuracy: 91.9000015258789\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_54.h5\n",
      "Training Epoch 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Loss: 0.014276651665568352, Accuracy: 99.51399993896484, Test Loss: 0.4441272020339966, Test Accuracy: 92.23999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_55.h5\n",
      "Training Epoch 56\n",
      "Epoch 56, Loss: 0.012560106813907623, Accuracy: 99.55599975585938, Test Loss: 0.4722616374492645, Test Accuracy: 91.81999969482422\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_56.h5\n",
      "Training Epoch 57\n",
      "Epoch 57, Loss: 0.011972322128713131, Accuracy: 99.58599853515625, Test Loss: 0.44555702805519104, Test Accuracy: 92.19999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_57.h5\n",
      "Training Epoch 58\n",
      "Epoch 58, Loss: 0.011246572248637676, Accuracy: 99.62000274658203, Test Loss: 0.4450986981391907, Test Accuracy: 92.22000122070312\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_58.h5\n",
      "Training Epoch 59\n",
      "Epoch 59, Loss: 0.009571514092385769, Accuracy: 99.68799591064453, Test Loss: 0.4658750593662262, Test Accuracy: 91.97999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_59.h5\n",
      "Training Epoch 60\n",
      "Epoch 60, Loss: 0.010223080404102802, Accuracy: 99.65999603271484, Test Loss: 0.4579503536224365, Test Accuracy: 92.23999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_60.h5\n",
      "Training Epoch 61\n",
      "Epoch 61, Loss: 0.00975876860320568, Accuracy: 99.68399810791016, Test Loss: 0.46356818079948425, Test Accuracy: 92.23999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_61.h5\n",
      "Training Epoch 62\n",
      "Epoch 62, Loss: 0.008961405605077744, Accuracy: 99.72200012207031, Test Loss: 0.47882938385009766, Test Accuracy: 92.07999420166016\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_62.h5\n",
      "Training Epoch 63\n",
      "Epoch 63, Loss: 0.00838692020624876, Accuracy: 99.70600128173828, Test Loss: 0.46732985973358154, Test Accuracy: 92.47999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_63.h5\n",
      "Training Epoch 64\n",
      "Epoch 64, Loss: 0.008837899193167686, Accuracy: 99.697998046875, Test Loss: 0.4708009958267212, Test Accuracy: 92.04000091552734\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_64.h5\n",
      "Training Epoch 65\n",
      "Epoch 65, Loss: 0.008088368922472, Accuracy: 99.72799682617188, Test Loss: 0.4599798619747162, Test Accuracy: 92.27999877929688\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_65.h5\n",
      "Training Epoch 66\n",
      "Epoch 66, Loss: 0.00811556726694107, Accuracy: 99.70999908447266, Test Loss: 0.46214401721954346, Test Accuracy: 91.95999908447266\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_66.h5\n",
      "Training Epoch 67\n",
      "Epoch 67, Loss: 0.007763780187815428, Accuracy: 99.73400115966797, Test Loss: 0.48448097705841064, Test Accuracy: 92.18999481201172\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_67.h5\n",
      "Training Epoch 68\n",
      "Epoch 68, Loss: 0.006664476357400417, Accuracy: 99.80000305175781, Test Loss: 0.4717698395252228, Test Accuracy: 92.31999969482422\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_68.h5\n",
      "Training Epoch 69\n",
      "Epoch 69, Loss: 0.005901118274778128, Accuracy: 99.79399871826172, Test Loss: 0.4954831600189209, Test Accuracy: 91.93000030517578\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_69.h5\n",
      "Training Epoch 70\n",
      "Epoch 70, Loss: 0.007578880060464144, Accuracy: 99.76200103759766, Test Loss: 0.4863061010837555, Test Accuracy: 92.18999481201172\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_70.h5\n",
      "Training Epoch 71\n",
      "Epoch 71, Loss: 0.006496751215308905, Accuracy: 99.79000091552734, Test Loss: 0.4673730731010437, Test Accuracy: 92.15999603271484\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_71.h5\n",
      "Training Epoch 72\n",
      "Epoch 72, Loss: 0.005011148285120726, Accuracy: 99.85399627685547, Test Loss: 0.48599541187286377, Test Accuracy: 92.07999420166016\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_72.h5\n",
      "Training Epoch 73\n",
      "Epoch 73, Loss: 0.00523169944062829, Accuracy: 99.83799743652344, Test Loss: 0.48488515615463257, Test Accuracy: 92.25\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_73.h5\n",
      "Training Epoch 74\n",
      "Epoch 74, Loss: 0.0064584012143313885, Accuracy: 99.77999877929688, Test Loss: 0.48382410407066345, Test Accuracy: 92.0199966430664\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_74.h5\n",
      "Training Epoch 75\n",
      "Epoch 75, Loss: 0.004335482604801655, Accuracy: 99.86199951171875, Test Loss: 0.4802175462245941, Test Accuracy: 92.27999877929688\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_75.h5\n",
      "Training Epoch 76\n",
      "Epoch 76, Loss: 0.003805232234299183, Accuracy: 99.88999938964844, Test Loss: 0.4856230914592743, Test Accuracy: 92.19999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_76.h5\n",
      "Training Epoch 77\n",
      "Epoch 77, Loss: 0.005240119528025389, Accuracy: 99.82200622558594, Test Loss: 0.49841949343681335, Test Accuracy: 91.97000122070312\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_77.h5\n",
      "Training Epoch 78\n",
      "Epoch 78, Loss: 0.005774201825261116, Accuracy: 99.81200408935547, Test Loss: 0.4865618348121643, Test Accuracy: 92.44999694824219\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_78.h5\n",
      "Training Epoch 79\n",
      "Epoch 79, Loss: 0.005613934248685837, Accuracy: 99.81600189208984, Test Loss: 0.4954829514026642, Test Accuracy: 92.22999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_79.h5\n",
      "Training Epoch 80\n",
      "Epoch 80, Loss: 0.004336474929004908, Accuracy: 99.86000061035156, Test Loss: 0.4824662506580353, Test Accuracy: 92.25999450683594\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_80.h5\n",
      "Training Epoch 81\n",
      "Epoch 81, Loss: 0.004660031758248806, Accuracy: 99.85399627685547, Test Loss: 0.49090778827667236, Test Accuracy: 92.1199951171875\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_81.h5\n",
      "Training Epoch 82\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from checkpoint: ./checkpoints/ckpt_epoch_81.ckpt\n",
      "Restored from epoch 81: \n",
      "Training Epoch 82\n",
      "Epoch 82, Loss: 0.25105977058410645, Accuracy: 91.61000061035156, Test Loss: 0.46600013971328735, Test Accuracy: 86.45999908447266\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_82.h5\n",
      "Training Epoch 83\n",
      "Epoch 83, Loss: 0.16408072412014008, Accuracy: 94.28600311279297, Test Loss: 0.42047056555747986, Test Accuracy: 88.75\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_83.h5\n",
      "Training Epoch 84\n",
      "Epoch 84, Loss: 0.12518396973609924, Accuracy: 95.50199890136719, Test Loss: 0.3951683044433594, Test Accuracy: 88.91999816894531\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_84.h5\n",
      "Training Epoch 85\n",
      "Epoch 85, Loss: 0.10197114944458008, Accuracy: 96.38800048828125, Test Loss: 0.518020510673523, Test Accuracy: 87.4000015258789\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_85.h5\n",
      "Training Epoch 86\n",
      "Epoch 86, Loss: 0.08748015016317368, Accuracy: 96.94200134277344, Test Loss: 0.417152464389801, Test Accuracy: 89.7800064086914\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_86.h5\n",
      "Training Epoch 87\n",
      "Epoch 87, Loss: 0.07225903123617172, Accuracy: 97.49400329589844, Test Loss: 0.38012009859085083, Test Accuracy: 90.80999755859375\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_87.h5\n",
      "Training Epoch 88\n",
      "Epoch 88, Loss: 0.055968403816223145, Accuracy: 98.0719985961914, Test Loss: 0.3997492790222168, Test Accuracy: 90.38999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_88.h5\n",
      "Training Epoch 89\n",
      "Epoch 89, Loss: 0.05138276889920235, Accuracy: 98.25, Test Loss: 0.44459325075149536, Test Accuracy: 90.30000305175781\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_89.h5\n",
      "Training Epoch 90\n",
      "Epoch 90, Loss: 0.045053184032440186, Accuracy: 98.33999633789062, Test Loss: 0.4147951006889343, Test Accuracy: 91.22999572753906\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_90.h5\n",
      "Training Epoch 91\n",
      "Epoch 91, Loss: 0.03710164502263069, Accuracy: 98.71199798583984, Test Loss: 0.41271916031837463, Test Accuracy: 90.98999786376953\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_91.h5\n",
      "Training Epoch 92\n",
      "Epoch 92, Loss: 0.030238330364227295, Accuracy: 98.99200439453125, Test Loss: 0.4077010452747345, Test Accuracy: 91.63999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_92.h5\n",
      "Training Epoch 93\n",
      "Epoch 93, Loss: 0.02867860533297062, Accuracy: 99.00399780273438, Test Loss: 0.47847458720207214, Test Accuracy: 90.8699951171875\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_93.h5\n",
      "Training Epoch 94\n",
      "Epoch 94, Loss: 0.021735860034823418, Accuracy: 99.2560043334961, Test Loss: 0.43172067403793335, Test Accuracy: 91.8499984741211\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_94.h5\n",
      "Training Epoch 95\n",
      "Epoch 95, Loss: 0.02253839559853077, Accuracy: 99.20800018310547, Test Loss: 0.45809853076934814, Test Accuracy: 91.38999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_95.h5\n",
      "Training Epoch 96\n",
      "Epoch 96, Loss: 0.020087163895368576, Accuracy: 99.28600311279297, Test Loss: 0.4378494620323181, Test Accuracy: 91.86000061035156\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_96.h5\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from checkpoint: ./checkpoints/ckpt_epoch_96.ckpt\n",
      "Restored from epoch 96: \n",
      "Training Epoch 97\n",
      "Epoch 97, Loss: 0.1241103783249855, Accuracy: 95.63199615478516, Test Loss: 0.48632463812828064, Test Accuracy: 88.20999908447266\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_97.h5\n",
      "Training Epoch 98\n",
      "Epoch 98, Loss: 0.0968347117304802, Accuracy: 96.697998046875, Test Loss: 0.44599729776382446, Test Accuracy: 88.38999938964844\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_98.h5\n",
      "Training Epoch 99\n",
      "Epoch 99, Loss: 0.07595165073871613, Accuracy: 97.33599853515625, Test Loss: 0.38402116298675537, Test Accuracy: 90.58000183105469\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_99.h5\n",
      "Training Epoch 100\n",
      "Epoch 100, Loss: 0.05720989778637886, Accuracy: 98.01800537109375, Test Loss: 0.4196314811706543, Test Accuracy: 90.80999755859375\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_100.h5\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted previous saved models.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_path):\n",
    "    for filename in os.listdir(model_path):\n",
    "        file_path = os.path.join(model_pathmodel_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(\"Deleted previous saved models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fArqxHakePav",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f0dd9a18828>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f0dd9a69c18>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./save_model/ResNet18/assets\n",
      "Model saved to ./save_model/ResNet18\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save(model_path)\n",
    "print(\"Model saved to ./save_model/ResNet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsUE2oxdRM1H"
   },
   "source": [
    "### Calculation of Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TpIl5EZiPyls"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "import time\n",
    "#########from utils.utils import set_seed, cifar10_std, cifar10_mean\n",
    "from utils.ResNet18_trainer import std, mean\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from utils.ResNet18_trainer import ResNet18_trainer, load_cifar10_dataset\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.Shapley_Value_Calculator import getShapley_pixel, getShapley_freq, getShapley_freq_dis, sample_mask, getShapley_freq_softmax, visual_shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bmii_IhdPyn-"
   },
   "outputs": [],
   "source": [
    "#model_name = 'ResNet18'\n",
    "#dataset_name = 'cifar10'\n",
    "#data_path = '~/data'\n",
    "output_path = './output'\n",
    "model_path = \"./save_model/ResNet18\"\n",
    "sample_times = 2  #000\n",
    "#num_per_class = 150\n",
    "#testdata = False\n",
    "mask_size = 3 #16\n",
    "n_per_batch = 1\n",
    "start_num = 0\n",
    "get_freq_by_dis = False\n",
    "fix_mask = False\n",
    "split_n = 1\n",
    "static_center = False\n",
    "#norm = True\n",
    "batch_size = 64\n",
    "num_classes=10\n",
    "seed = 111\n",
    "\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hXX39alyPyun"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(model_path, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_cifar10_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gYeAt1MUPywK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_img: (10, 32, 32, 3)\n",
      "output: tf.Tensor(\n",
      "[[0.23004371 0.08545776 0.08545773 0.08545984 0.08547141 0.08546851\n",
      "  0.08545774 0.08624364 0.08548196 0.08545772]\n",
      " [0.23042291 0.08543406 0.08543403 0.08543575 0.08544731 0.08544244\n",
      "  0.08543404 0.08605764 0.08545781 0.08543402]\n",
      " [0.23179635 0.08534768 0.0853477  0.08535112 0.08535769 0.08539087\n",
      "  0.0853478  0.08535969 0.08535343 0.08534768]\n",
      " [0.08670476 0.08670474 0.08670475 0.20824602 0.08671855 0.08680054\n",
      "  0.09800629 0.08670474 0.08670482 0.08670474]\n",
      " [0.08856246 0.08856243 0.08856244 0.14857693 0.08858189 0.08949233\n",
      "  0.1419742  0.08856243 0.08856256 0.08856243]\n",
      " [0.08855362 0.08855359 0.0885536  0.15008233 0.08857064 0.08945534\n",
      "  0.14056994 0.08855359 0.08855373 0.08855359]\n",
      " [0.20484433 0.08692041 0.08693397 0.08700698 0.08738143 0.08692417\n",
      "  0.09543724 0.0869197  0.09071218 0.08691965]\n",
      " [0.21140927 0.08656679 0.08658959 0.08660477 0.08709224 0.0865689\n",
      "  0.09136546 0.08656618 0.09067071 0.08656615]\n",
      " [0.22586733 0.08571618 0.08588831 0.08572442 0.08598114 0.08571671\n",
      "  0.08784936 0.08571582 0.0858248  0.08571594]\n",
      " [0.22746493 0.08561844 0.08581486 0.0856236  0.08585925 0.08561867\n",
      "  0.08705109 0.08561813 0.08571283 0.08561824]], shape=(10, 10), dtype=float32)\n",
      "y: tf.Tensor([0 0 0 3 3 3 0 0 0 0], shape=(10,), dtype=int64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 4, 5, 6, 7, 8, 3, 2])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-02afb54620fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mn_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_per_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0msplit_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mstatic_center\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/e4040-2024fall-project-myzh/utils/Shapley_Value_Calculator.py\u001b[0m in \u001b[0;36mgetShapley_freq_softmax\u001b[0;34m(img, label, model, sample_times, mask_size, k, n_per_batch, split_n, static_center, fix_masks, mask_path)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# shap_value = tf.tensor_scatter_nd_add(shap_value,tf.reshape(order, (-1, 1)),dy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mshap_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1007\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m       \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 4, 5, 6, 7, 8, 3, 2])"
     ]
    }
   ],
   "source": [
    "count = [0 for _ in range(num_classes)]\n",
    "\n",
    "dataset = test_ds\n",
    "\n",
    "for img, y in dataset:\n",
    "    bs, w, h, c = img.shape\n",
    "    img, y = tf.convert_to_tensor(img), tf.convert_to_tensor(y)\n",
    "\n",
    "    for k in range(bs):\n",
    "        if count[y[k].numpy()[0]] < 0:\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "        elif count[y[k].numpy()[0]] < 50:\n",
    "            shap_value = getShapley_freq_softmax(\n",
    "                img, y, model, sample_times, mask_size, k,\n",
    "                n_per_batch=n_per_batch,\n",
    "                split_n=split_n,\n",
    "                static_center=False\n",
    "            )\n",
    "\n",
    "            shap_path = os.path.join('', \"shap_result\", f\"{y[k].numpy()[0]}\")\n",
    "            Path(shap_path).mkdir(parents=True, exist_ok=True)\n",
    "            np.save(os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}_freq.npy\"), shap_value)\n",
    "\n",
    "            visual_path = os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}_freq_shap.png\")\n",
    "            visual_shap(shap_value, mask_size, mask_size, visual_path)\n",
    "\n",
    "            raw_img = img[k].numpy()\n",
    "            img_path = os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}.png\")\n",
    "            \n",
    "            for j in range(3):\n",
    "                raw_img[:, :, j] = raw_img[:, :, j] * std[j] + mean[j]\n",
    "            save_img(img_path, raw_img)\n",
    "\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "            print(f\"Class {y[k].numpy()[0]} sample {count[y[k].numpy()[0]]} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PrefetchDataset' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-21ad2a0d11fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'PrefetchDataset' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY9zufwfPy2k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbb: tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "aaa =np.array([2.33248621e-02, 7.49617757e-04, 3.52356344e-01, 2.36003712e-01,\n",
    "  9.61460173e-02, 2.44320214e-01, 2.27117091e-02, 1.11861918e-02,\n",
    "  1.22030042e-02, 9.98409465e-04])\n",
    "bbb = tf.argmax(aaa, axis=-1)\n",
    "print(\"bbb:\", bbb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.33248621e-02 7.49617757e-04 3.52356344e-01 2.36003712e-01\n",
      "  9.61460173e-02 2.44320214e-01 2.27117091e-02 1.11861918e-02\n",
      "  1.22030042e-02 9.98409465e-04]\n",
      " [9.09662023e-02 4.22474509e-03 5.70751190e-01 6.26687333e-02\n",
      "  1.40823543e-01 2.19893865e-02 3.51789556e-02 6.78093778e-03\n",
      "  6.36044666e-02 3.01178894e-03]\n",
      " [7.75583163e-02 1.81420823e-03 5.48251152e-01 1.09931611e-01\n",
      "  1.37956142e-01 5.25747426e-02 2.28246413e-02 7.12314062e-03\n",
      "  4.03941609e-02 1.57185376e-03]\n",
      " [1.13995209e-01 2.42476771e-03 6.25434279e-01 6.86364323e-02\n",
      "  8.29450041e-02 2.49087643e-02 2.15078499e-02 5.19478740e-03\n",
      "  5.29900864e-02 1.96281215e-03]\n",
      " [1.78613551e-02 1.25616498e-03 5.21133184e-01 1.04399949e-01\n",
      "  2.22250283e-01 6.71412796e-02 5.01192883e-02 6.65253447e-03\n",
      "  8.36848561e-03 8.17465712e-04]\n",
      " [3.92282233e-02 2.46568373e-03 5.06564260e-01 1.30733043e-01\n",
      "  1.67187288e-01 7.40858987e-02 4.40960415e-02 8.33939295e-03\n",
      "  2.52674446e-02 2.03283480e-03]\n",
      " [2.30960790e-02 5.69595257e-04 5.77167809e-01 1.05154924e-01\n",
      "  1.07835747e-01 1.43796980e-01 2.26223040e-02 1.39773833e-02\n",
      "  5.15025575e-03 6.28899958e-04]\n",
      " [7.17422590e-02 2.30351859e-03 5.61578810e-01 8.04085061e-02\n",
      "  1.74368396e-01 3.17138657e-02 3.61147337e-02 4.68962360e-03\n",
      "  3.54961567e-02 1.58405176e-03]\n",
      " [2.06858888e-02 8.63178109e-04 5.70412815e-01 1.26658723e-01\n",
      "  1.19378813e-01 1.17924340e-01 2.81894729e-02 8.56406521e-03\n",
      "  6.56403368e-03 7.58707640e-04]\n",
      " [4.58448417e-02 3.01609957e-03 4.86208290e-01 1.84218124e-01\n",
      "  9.02689099e-02 7.68279657e-02 6.93701431e-02 9.16627143e-03\n",
      "  3.15675065e-02 3.51181580e-03]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'argmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f0396d4881ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 输出预测结果 (例如显示前10个样本的预测标签)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'argmax'"
     ]
    }
   ],
   "source": [
    "# 输出预测结果 (例如显示前10个样本的预测标签)\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "print(predicted_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1QgHrNGPy4j"
   },
   "source": [
    "### Reconstructing Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58f3bc460585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfft2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifft2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'save_img'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.signal import fft2d, ifft2d\n",
    "from tensorflow.keras.utils import save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"your_data_path\"\n",
    "recon_path = os.path.join(path, \"reconstruction\")\n",
    "ifft_path = os.path.join(path, \"ifft\")\n",
    "shap_path = os.path.join(path, \"shap_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(recon_path, exist_ok=True)\n",
    "os.makedirs(ifft_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = False  # 替代 cfg.train.norm\n",
    "cifar10_mean = [0.4914, 0.4822, 0.4465]\n",
    "cifar10_std = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据增强操作\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = resize(img, [32, 32])  # 假设目标是 CIFAR-10 大小\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历类文件夹\n",
    "classes = os.listdir(shap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理每个类\n",
    "for class_name in classes:\n",
    "    result_path = os.path.join(shap_path, class_name)\n",
    "    if not os.path.isdir(result_path):\n",
    "        continue\n",
    "\n",
    "    files = os.listdir(result_path)\n",
    "    for file in files:\n",
    "        if \".png\" not in file or \"shap\" in file:\n",
    "            continue\n",
    "\n",
    "        # 加载图片\n",
    "        img_path = os.path.join(result_path, file)\n",
    "        img = preprocess_image(img_path)\n",
    "\n",
    "        # FFT 转换\n",
    "        freq = fft2d(tf.cast(img, tf.complex64))\n",
    "\n",
    "        # 加载频域 shap 值\n",
    "        freq_shap_file = file.split('.')[0] + \"_freq.npy\"\n",
    "        freq_shap_path = os.path.join(result_path, freq_shap_file)\n",
    "        freq_shap = np.load(freq_shap_path)\n",
    "        mask_size = int(math.sqrt(freq_shap.size))\n",
    "        freq_shap = tf.reshape(freq_shap, [1, mask_size, mask_size])\n",
    "\n",
    "        # 扩展为多通道\n",
    "        freq_shap = tf.tile(freq_shap, [3, 1, 1])  # 假设 3 个通道\n",
    "        freq_shap = tf.image.resize(freq_shap, [img.shape[0], img.shape[1]])\n",
    "\n",
    "        # 构造正负掩码\n",
    "        mask_pos = tf.cast(freq_shap > 0, tf.complex64)\n",
    "        mask_neg = tf.cast(freq_shap < 0, tf.complex64)\n",
    "\n",
    "        # 去除中心频率\n",
    "        mask_pos = tf.tensor_scatter_nd_update(\n",
    "            mask_pos, [[mask_pos.shape[1] // 2, mask_pos.shape[2] // 2]], [0]\n",
    "        )\n",
    "        mask_neg = tf.tensor_scatter_nd_update(\n",
    "            mask_neg, [[mask_neg.shape[1] // 2, mask_neg.shape[2] // 2]], [0]\n",
    "        )\n",
    "\n",
    "        # 生成正负频域图片\n",
    "        pos_freq = freq * mask_pos\n",
    "        neg_freq = freq * mask_neg\n",
    "\n",
    "        pos_img = tf.math.real(ifft2d(pos_freq))\n",
    "        neg_img = tf.math.real(ifft2d(neg_freq))\n",
    "\n",
    "        # 去标准化\n",
    "        for c in range(3):\n",
    "            pos_img[..., c] = pos_img[..., c] * std[c] + mean[c]\n",
    "            neg_img[..., c] = neg_img[..., c] * std[c] + mean[c]\n",
    "\n",
    "        # 保存图片\n",
    "        recon_class_path = os.path.join(recon_path, class_name)\n",
    "        os.makedirs(recon_class_path, exist_ok=True)\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_pos.png\"), pos_img)\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_neg.png\"), neg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ResNet18 under AT with CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
