{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm-nwhNRQ8wy"
   },
   "source": [
    "## E4040 2024 Fall Project\n",
    "### Improving CNN Robustness via CS Shapley Value-guided Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VW8-sXpHQ69k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEhf0dW5Qgdw"
   },
   "source": [
    "### Import CIFAR-10 data and training ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hi8OkdYcSEq7"
   },
   "outputs": [],
   "source": [
    "from utils.ResNet18_trainer import ResNet18_trainer, load_cifar10_dataset#, delete_previous_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "luF2f1RQeQAu"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "decay = 0.0005\n",
    "log_period = 100\n",
    "epochs=2  #120\n",
    "num_classes=10\n",
    "checkpoint_dir=\"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_cifar10_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZaCpuzjJeP-n"
   },
   "outputs": [],
   "source": [
    "trainer = ResNet18_trainer(\n",
    "    train_ds=train_ds,\n",
    "    test_ds=test_ds,\n",
    "    num_classes=num_classes,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    decay=decay,\n",
    "    checkpoint_dir=checkpoint_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted previous checkpoints.\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    for filename in os.listdir(checkpoint_dir):\n",
    "        file_path = os.path.join(checkpoint_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    print(\"Deleted previous checkpoints.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Y_2-LAmwePdc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting from scratch.\n",
      "Training Epoch 1\n",
      "Epoch 1, Loss: 1.72958505153656, Accuracy: 38.86600112915039, Test Loss: 1.3595706224441528, Test Accuracy: 49.97999954223633\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_1.h5\n",
      "Training Epoch 2\n",
      "Epoch 2, Loss: 1.6087888479232788, Accuracy: 45.30799865722656, Test Loss: 1.3945369720458984, Test Accuracy: 52.52000045776367\n",
      "Checkpoint saved at: ./checkpoints/ckpt_epoch_2.h5\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fArqxHakePav",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f0fb1eb60b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f0fb1efb898>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: save_model/assets\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save(\"~/save_model\")\n",
    "print(\"Model saved to ~/save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[8.2136859e-04, 9.8826218e-05, 8.2579497e-03, 3.1761732e-03,\n",
       "        8.6224480e-03, 4.8236409e-04, 9.7743452e-01, 2.0195763e-04,\n",
       "        3.0673956e-04, 5.9767353e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainer.model.build((None, 32, 32, 3))\n",
    "#dummy_input = tf.random.normal((1, 32, 32, 3))\n",
    "#trainer.model(dummy_input, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsUE2oxdRM1H"
   },
   "source": [
    "### Calculation of Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpIl5EZiPyls"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "import time\n",
    "#########from utils.utils import set_seed, cifar10_std, cifar10_mean\n",
    "from utils.ResNet18_trainer import std, mean\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "\n",
    "\n",
    "from utils.Shapley_sample import getShapley_pixel, getShapley_freq, getShapley_freq_dis, sample_mask, getShapley_freq_softmax, visual_shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmii_IhdPyn-"
   },
   "outputs": [],
   "source": [
    "model_name = 'ResNet18'\n",
    "dataset_name = 'cifar10'\n",
    "data_path = '~/data'\n",
    "output_path = './output'\n",
    "model_path = \"./save_model\"\n",
    "sample_times = 2000\n",
    "num_per_class = 150\n",
    "#testdata = False\n",
    "mask_size = 16\n",
    "n_per_batch = 1\n",
    "start_num = 0\n",
    "get_freq_by_dis = False\n",
    "fix_mask = False\n",
    "split_n = 1\n",
    "static_center = False\n",
    "#norm = True\n",
    "batchsize = 64\n",
    "seed = 111\n",
    "\n",
    "set_seed(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaowX_CcPyqQ"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIzrSYEgPysV"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batchsize)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXX39alyPyun"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYeAt1MUPywK"
   },
   "outputs": [],
   "source": [
    "count = [0 for _ in range(num_classes)]\n",
    "\n",
    "dataset = test_dataset\n",
    "for img, y in dataset:\n",
    "    bs, w, h, c = img.shape\n",
    "    img, y = tf.convert_to_tensor(img), tf.convert_to_tensor(y)\n",
    "\n",
    "    for k in range(bs):\n",
    "        if count[y[k].numpy()[0]] < 0:\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "        elif count[y[k].numpy()[0]] < 50:\n",
    "            shap_value = getShapley_freq_softmax(\n",
    "                img, y, model, sample_times, mask_size, k,\n",
    "                n_per_batch=n_per_batch,\n",
    "                split_n=split_n,\n",
    "                static_center=False\n",
    "            )\n",
    "\n",
    "            shap_path = os.path.join('', \"shap_result\", f\"{y[k].numpy()[0]}\")\n",
    "            Path(shap_path).mkdir(parents=True, exist_ok=True)\n",
    "            np.save(os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}_freq.npy\"), shap_value)\n",
    "\n",
    "            visual_path = os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}_freq_shap.png\")\n",
    "            visual_shap(shap_value, mask_size, mask_size, visual_path)\n",
    "\n",
    "            raw_img = img[k].numpy()\n",
    "            img_path = os.path.join(shap_path, f\"{count[y[k].numpy()[0]]}.png\")\n",
    "            \n",
    "            for j in range(3):\n",
    "                raw_img[:, :, j] = raw_img[:, :, j] * std[j] + mean[j]\n",
    "            save_img(img_path, raw_img)\n",
    "\n",
    "            count[y[k].numpy()[0]] += 1\n",
    "            print(f\"Class {y[k].numpy()[0]} sample {count[y[k].numpy()[0]]} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY9zufwfPy2k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1QgHrNGPy4j"
   },
   "source": [
    "### Reconstructing Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.signal import fft2d, ifft2d\n",
    "from tensorflow.keras.utils import save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"your_data_path\"\n",
    "recon_path = os.path.join(path, \"reconstruction\")\n",
    "ifft_path = os.path.join(path, \"ifft\")\n",
    "shap_path = os.path.join(path, \"shap_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(recon_path, exist_ok=True)\n",
    "os.makedirs(ifft_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = False  # 替代 cfg.train.norm\n",
    "cifar10_mean = [0.4914, 0.4822, 0.4465]\n",
    "cifar10_std = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据增强操作\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = resize(img, [32, 32])  # 假设目标是 CIFAR-10 大小\n",
    "    return tf.convert_to_tensor(img, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历类文件夹\n",
    "classes = os.listdir(shap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理每个类\n",
    "for class_name in classes:\n",
    "    result_path = os.path.join(shap_path, class_name)\n",
    "    if not os.path.isdir(result_path):\n",
    "        continue\n",
    "\n",
    "    files = os.listdir(result_path)\n",
    "    for file in files:\n",
    "        if \".png\" not in file or \"shap\" in file:\n",
    "            continue\n",
    "\n",
    "        # 加载图片\n",
    "        img_path = os.path.join(result_path, file)\n",
    "        img = preprocess_image(img_path)\n",
    "\n",
    "        # FFT 转换\n",
    "        freq = fft2d(tf.cast(img, tf.complex64))\n",
    "\n",
    "        # 加载频域 shap 值\n",
    "        freq_shap_file = file.split('.')[0] + \"_freq.npy\"\n",
    "        freq_shap_path = os.path.join(result_path, freq_shap_file)\n",
    "        freq_shap = np.load(freq_shap_path)\n",
    "        mask_size = int(math.sqrt(freq_shap.size))\n",
    "        freq_shap = tf.reshape(freq_shap, [1, mask_size, mask_size])\n",
    "\n",
    "        # 扩展为多通道\n",
    "        freq_shap = tf.tile(freq_shap, [3, 1, 1])  # 假设 3 个通道\n",
    "        freq_shap = tf.image.resize(freq_shap, [img.shape[0], img.shape[1]])\n",
    "\n",
    "        # 构造正负掩码\n",
    "        mask_pos = tf.cast(freq_shap > 0, tf.complex64)\n",
    "        mask_neg = tf.cast(freq_shap < 0, tf.complex64)\n",
    "\n",
    "        # 去除中心频率\n",
    "        mask_pos = tf.tensor_scatter_nd_update(\n",
    "            mask_pos, [[mask_pos.shape[1] // 2, mask_pos.shape[2] // 2]], [0]\n",
    "        )\n",
    "        mask_neg = tf.tensor_scatter_nd_update(\n",
    "            mask_neg, [[mask_neg.shape[1] // 2, mask_neg.shape[2] // 2]], [0]\n",
    "        )\n",
    "\n",
    "        # 生成正负频域图片\n",
    "        pos_freq = freq * mask_pos\n",
    "        neg_freq = freq * mask_neg\n",
    "\n",
    "        pos_img = tf.math.real(ifft2d(pos_freq))\n",
    "        neg_img = tf.math.real(ifft2d(neg_freq))\n",
    "\n",
    "        # 去标准化\n",
    "        for c in range(3):\n",
    "            pos_img[..., c] = pos_img[..., c] * std[c] + mean[c]\n",
    "            neg_img[..., c] = neg_img[..., c] * std[c] + mean[c]\n",
    "\n",
    "        # 保存图片\n",
    "        recon_class_path = os.path.join(recon_path, class_name)\n",
    "        os.makedirs(recon_class_path, exist_ok=True)\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_pos.png\"), pos_img)\n",
    "        save_img(os.path.join(recon_class_path, f\"{file.split('.')[0]}_neg.png\"), neg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ResNet18 under AT with CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
